# -*- coding: utf-8 -*-
"""NLP for Data Viz Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16RPndmOwz14OdZT3VMN3AAvU-dHBOlgX
"""

import nltk
import string
from textblob import TextBlob

nltk.download('stopwords')
from nltk.corpus import stopwords
stoplist = stopwords.words('english') + ['though']

# Importing Data Files
import pandas as pd
import numpy  as np
products_df = pd.read_csv('/content/products.tsv', sep='\t', header=0)
reviews_df = pd.read_csv('/content/reviews.tsv', sep='\t', header=0)

pd.set_option('display.max_rows', None)

reviews_df['EnglishReview'] = np.where(reviews_df['languageCode.1']=='en-US', reviews_df['reviewText'], reviews_df['translation.reviewText'])

## Data Cleaning
reviews_df.loc[reviews_df['id']=='46952c82-d750-41c5-b8f2-92579bb8039c','languageCode'] = 'ru-RU'
reviews_df.loc[reviews_df['id']=='46952c82-d750-41c5-b8f2-92579bb8039c','languageCode.1'] = 'ru-RU'
reviews_df.loc[reviews_df['id']=='46952c82-d750-41c5-b8f2-92579bb8039c','translation.reviewText'] = "The mask, in principle, is cool. Made of pleasant natural fabric, thin. But!!! you need to know that after the first wash it does not significantly decrease in size. Suitable for a child or a girl with a small face. Therefore, for a small face - 5+++! For a standard adult - 4 not because of quality, but because of size"

reviews_df = reviews_df.drop_duplicates(inplace=False, ignore_index=False)
product_id = 101955
bad_reviews = reviews_df.loc[(reviews_df['productId']==product_id) & ((reviews_df['ratingValue']==40) | (reviews_df['ratingValue']==50))]['EnglishReview']#.apply(remove_stopwords,stopwords=bad_stopwords)
# bad_reviews.to_csv(filename,index=False)
bad_reviews

from sklearn.feature_extraction.text import CountVectorizer
c_vec = CountVectorizer(stop_words=stoplist, ngram_range=(2,3))
# matrix of ngrams
ngrams = c_vec.fit_transform(bad_reviews)
# count frequency of ngrams
count_values = ngrams.toarray().sum(axis=0)
# list of ngrams
vocab = c_vec.vocabulary_
df_ngram = pd.DataFrame(sorted([(count_values[i],k) for k,i in vocab.items()], reverse=True)
            ).rename(columns={0: 'frequency', 1:'bigram/trigram'})

df_ngram['polarity'] = df_ngram['bigram/trigram'].apply(lambda x: TextBlob(x).polarity)
df_ngram['subjective'] = df_ngram['bigram/trigram'].apply(lambda x: TextBlob(x).subjectivity)

df_ngram.loc[df_ngram['polarity']<-0.1]

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import NMF
from sklearn.pipeline import make_pipeline
tfidf_vectorizer = TfidfVectorizer(stop_words=stoplist, ngram_range=(2,3))
nmf = NMF(n_components=3)
pipe = make_pipeline(tfidf_vectorizer, nmf)
pipe.fit(bad_reviews)
def print_top_words(model, feature_names, n_top_words):
    for topic_idx, topic in enumerate(model.components_):
        message = "Topic #%d: " % topic_idx
        message += ", ".join([feature_names[i]
                             for i in topic.argsort()[:-n_top_words - 1:-1]])
        print(message)
    print()
print_top_words(nmf, tfidf_vectorizer.get_feature_names_out(), n_top_words=3)

"""**Review Tagging**

As a list in the dataframe
"""

chkdict = {
  'damage_words' : ['broke','tore','break','tear','torn','snapped','snap','fraying','fray'],
  'costly_words' : ['expensive','costly','pricy'],
  'economical_words': ['inexpensive','discount','bargain','cheap','affordable','economical','steal','offer'],
  'skin_words' : ['allergy','makeup','make-up','rashes','rash','swollen','cut','blood','sweat'],
  'fit_words' : ['small','fit','right','loose','big','small','large','little','smaller','larger'],
  'quality_words' : ['thick','thin','cotton','nylon','elastic','band'],
  'shipping_words' : ['shipped','late','arrived','early','packed','tax','import'],
  'fogging_words' : ['lenses','eyewear','glasses','fogging','mist'],
  'washing_words' : ['wash','washing','detergent','water','rinse','soap'],
  'water_test_words' : ['water test','water'],
  'injury_words' : ['injured','injure','blood','bruised','bruise'],
  'makeup_words' : ['makeup','make-up','make up','lipstick','mascara','eyeliner','smudge']
}
def check_in(text):
  lc_text = text.translate(str.maketrans('', '', string.punctuation))
  lc_text = lc_text.lower().split()
  rtags = []
  for key,value in chkdict.items():
    if any( i in value for i in lc_text):
      rtags.append(key)
  return rtags#','.join(rtags)

reviews_df['Tags'] = reviews_df['EnglishReview'].apply(check_in)
# reviews_df.loc[reviews_df['Tags']]
tag_df = reviews_df[reviews_df['Tags'].map(lambda tags: 'costly_words' in tags or 'economical_words' in tags)]
pd.set_option('max_colwidth', None)
# Slice Positive Reviews
tag_df = tag_df.loc[((tag_df['ratingValue']==40) | (tag_df['ratingValue']==50))]
# Slice Negative Reviews
# tag_df = tag_df.loc[((tag_df['ratingValue']==10) | (tag_df['ratingValue']==20) | (tag_df['ratingValue']==30))]
tagdf = tag_df[['productId','EnglishReview','Tags']]
tagdf = tagdf.loc[tagdf['productId']==101955]
# Reviews of Mask 101955 that have positive things about price.
tagdf

file_name = "kitsch_10s.csv"
reviews_df.loc[(reviews_df['productId']==100237) & (reviews_df['ratingValue']==10)]['EnglishReview'].to_csv(file_name,index=False,header=False)

word_counter = 0
limit = 2400
content = []
with open(file_name) as file:
  for item in file:
    words_list = item.split()
    length_of_line = len(words_list)
    word_counter+=length_of_line
    content.append(item)
    if word_counter > limit - 10:
      print("Inserted")
      word_counter = 0
      content.append("\n")
      content.append("---------------------------")
      content.append("\n")
file.close()
print(word_counter)
# print(content)
fout = open(file_name, 'w')
fout.writelines(content)
fout.close()

# !pip install openai

# import os
# import openai

# openai.api_key = ""

# openai.ChatCompletion.create(
#   model="gpt-3.5-turbo",
#   messages=[
#     {"role": "user", "content": "Hello ChatGPT, does this work?"}
#   ]
#   )
# print(response.choices[0].message.content)

import numpy as np
import requests
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt
import matplotlib as mpl
from wordcloud import WordCloud,STOPWORDS

def read_img_from_url(url):
    response = requests.get(url)
    img = Image.open(BytesIO(response.content))
    img_matrix = np.array(img)
    return img_matrix

def read_txt_from_url(url, *size):
    text = requests.get(url).text
    wc = WordCloud(background_color="white", max_words=100 , max_font_size=100, width=size[0], height=size[1], random_state=42)
    wc.generate(text)
    return wc.to_array()

img_url = "https://cdn.shopify.com/s/files/1/0017/0878/5773/products/sunjoyfacemask_1200x1200.jpg?v=1622007495"
img_matrix = read_img_from_url(img_url)
txt_url = "https://en.wikipedia.org/wiki/Python_(programming_language)"
txt_matrix = read_txt_from_url(txt_url, *img_matrix.shape)

print(img_matrix.shape, txt_matrix.shape)

plt.figure(figsize=(10, 10), dpi=300)
plt.imshow(img_matrix)
plt.axis('off')
plt.show()

negative_reviews = pd.read_csv("/content/Mask Mandate TimeLine - US - DVD Project - Sheet9 (4).csv")

negative_reviews

d = negative_reviews.set_index('Text').to_dict()
d = d['Count']

# BRAILLE_PATTERN_BLANK = "â €"
# neg_list = list(negative_reviews['Text'])
# for ctr,i in enumerate(neg_list):
#   i=i.replace(" "," ")
#   neg_list[ctr]=i
# # neg_list
# neg_reviews=",".join(neg_list)

# wc = WordCloud(background_color="white", max_words=2000,
#                stopwords=STOPWORDS, max_font_size=256,
#                random_state=42, width=500, height=500)
# wc.generate(neg_reviews)
# plt.imshow(wc, interpolation="bilinear")
# plt.axis('off')
# plt.show()

# wordcloud = WordCloud(width=900,height=500, max_words=1628,relative_scaling=1,normalize_plurals=False).generate_from_frequencies(d)
# plt.imshow(wordcloud, interpolation='bilinear')
# plt.axis("off")
# plt.show()

mask = np.array(Image.open('/content/mask6e2.jpg'))
cmap = mpl.cm.Reds(np.linspace(0,1,20))
cmap = mpl.colors.ListedColormap(cmap[-10:,:-1])
font_path = '/content/couture-bld.otf'
wc = WordCloud(stopwords=STOPWORDS, mask=mask, background_color="white", font_path=font_path,
               max_words=2000, min_font_size=80, max_font_size=256,
               random_state=40, width=mask.shape[1],
               height=mask.shape[0],colormap=cmap,contour_color='grey',contour_width=1)
# wc.generate(neg_reviews)
wc.generate_from_frequencies(d)
plt.figure(figsize=(36,8),dpi=300)
plt.imshow(wc, interpolation="bilinear")
plt.axis('off')
plt.show()

positive_reviews = pd.read_csv("/content/Mask Mandate TimeLine - US - DVD Project - SunJoy Positive.csv")

d = positive_reviews.set_index('Text').to_dict()
d = d['Count']
word_list=[]
for k,v in d.items():
  for i in range(v):
    word_list.append(k)
positive_corpus = ",".join(word_list)
mask = np.array(Image.open('/content/mask6e2.jpg'))
cmap = mpl.cm.Greens(np.linspace(0,1,20))
cmap = mpl.colors.ListedColormap(cmap[-10:,:-1])
font_path = '/content/couture-bld.otf'
wc = WordCloud(stopwords=STOPWORDS, mask=mask, background_color="white",font_path=font_path,
               max_words=2000, min_font_size=60, max_font_size=256,
               random_state=42, width=mask.shape[1],
               height=mask.shape[0],colormap=cmap,contour_color='grey',contour_width=1)
# wc.generate(positive_corpus)
wc.generate_from_frequencies(d)
plt.figure(figsize=(36,8),dpi=300)
plt.imshow(wc, interpolation="bilinear")
plt.axis('off')
plt.show()

country_dict = {'en-US': 'United States', 'ru-RU': 'Russia', 'ar-SA': 'Saudi Arabia', 'he-IL': 'Israel', 'ja-JP': 'Japan', 'fr-FR': 'France', 'zh-TW': 'Taiwan', 'ko-KR': 'Korea', 'es-MX': 'Mexico', 'zh-CN': 'China', 'de-DE': 'Germany', 'pt-BR': 'Brazil'}
def get_country(text):
  return country_dict[text]
reviews_df['Country'] = reviews_df['languageCode'].apply(get_country)

reviews = reviews_df.loc[reviews_df['Country']=='United States']['EnglishReview']

usa_review_list = list(reviews)
usa_reviews = ",".join(usa_review_list)
mask = np.array(Image.open('/content/USA.jpeg'))
cmap = mpl.cm.Blues(np.linspace(0,1,20))
cmap = mpl.colors.ListedColormap(cmap[-10:,:-1])
wc = WordCloud(stopwords=STOPWORDS, mask=mask, background_color="white",
               max_words=2000, min_font_size=4, max_font_size=256,
               random_state=42, width=mask.shape[1],
               height=mask.shape[0],colormap=cmap,contour_color='grey',contour_width=0)
wc.generate(usa_reviews)
# wc.generate_from_frequencies(d)
plt.figure(figsize=(36,8),dpi=300)
plt.imshow(wc, interpolation="bilinear")
plt.axis('off')
plt.show()

reviews = reviews_df.loc[reviews_df['Country']=='Russia']['EnglishReview']

russia_review_list = list(reviews)
russia_reviews = ",".join(usa_review_list)
mask = np.array(Image.open('/content/Russia.jpeg'))
cmap = mpl.cm.Blues(np.linspace(0,1,20))
cmap = mpl.colors.ListedColormap(cmap[-10:,:-1])
wc = WordCloud(stopwords=STOPWORDS, mask=mask, background_color="white",
               max_words=2000, min_font_size=4, max_font_size=256,
               random_state=42, width=mask.shape[1],
               height=mask.shape[0],colormap=cmap,contour_color='grey',contour_width=0)
wc.generate(russia_reviews)
# wc.generate_from_frequencies(d)
plt.figure(figsize=(36,8),dpi=300)
plt.imshow(wc, interpolation="bilinear")
plt.axis('off')
plt.show()